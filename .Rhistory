par(mfrow=c(3,1))
# make our random samples - in this case we're sampling the community 999 times!
dSamp <- replicate(999, dComm(n=sampleCount))
# how many species did we find in our n samples?
dRich <- apply(dSamp, 2, function(x){length(unique(x))})
table(dRich)
# plot compared to our "true" richness
hist(dRich, xlim=c(0,max(trueRich[1])))
abline(v=max(trueRich[1]), col="red")
# do the same for other communities
aSamp <- replicate(999, aComm(n=sampleCount))
aRich <- apply(aSamp, 2, function(x){length(unique(x))})
table(aRich)
hist(aRich, xlim=c(0,max(trueRich[2])))
abline(v=max(trueRich[2]), col="red")
rSamp <- replicate(999, rComm(n=sampleCount))
rRich <- apply(rSamp, 2, function(x){length(unique(x))})
table(rRich)
hist(rRich, xlim=c(0,max(trueRich[3])))
abline(v=max(trueRich[3]), col="red")
# now when we compare communities, the paper says it's more important to
# have similar relative richnesses. So what proportion of each community's species
# did we get?
medRich <- c(median(dRich), median(aRich), median(rRich))
sapply(1:3, function(n){medRich[n] / trueRich[n]})
# and how to the relative richnesses of the true comms (compared to the blue comm)
# compare to the median of our samples
trueRich / trueRich[3]
medRich / medRich[3]
# Let's focus JUST on the average community for a spot
plot(x=NULL, y=NULL, xlim=c(1,1e6), ylim=c(1,150), log="xy",
xlab="log(individuals)", ylab="Species count")
# Let's focus JUST on the average community for a spot
dev.off()
plot(x=NULL, y=NULL, xlim=c(1,1e6), ylim=c(1,150), log="xy",
xlab="log(individuals)", ylab="Species count")
tempAcum <- spAcum(ssmat[2,])
lines(tempAcum$sp ~ tempAcum$ind, lwd=2)
# how do our samples at N match up to what we expected to see with that many
# individuals?
# how do our samples at N match up to what we expected to see with that many
# individuals?
boxplot(y=aRich, at=sampleCount, add=TRUE)
# how do our samples at N match up to what we expected to see with that many
# individuals?
boxplot(x=aRich, at=sampleCount, add=TRUE)
?boxplot
plot(x=NULL, y=NULL, xlim=c(1,1e6), ylim=c(1,150), log="xy",
xlab="log(individuals)", ylab="Species count")
tempAcum <- spAcum(ssmat[2,])
lines(tempAcum$sp ~ tempAcum$ind, lwd=2)
# how do our samples at N match up to what we expected to see with that many
# individuals?
boxplot(x=aRich, at=sampleCount, add=TRUE, border="red", col=NULL)
plot(x=NULL, y=NULL, xlim=c(1,1e6), ylim=c(1,150), log="xy",
xlab="log(individuals)", ylab="Species count")
tempAcum <- spAcum(ssmat[2,])
lines(tempAcum$sp ~ tempAcum$ind, lwd=2)
# how do our samples at N match up to what we expected to see with that many
# individuals?
boxplot(x=aRich, at=sampleCount, add=TRUE, border="red", fill=NULL)
dev.off()
plot(x=NULL, y=NULL, xlim=c(1,1e6), ylim=c(1,150), log="xy",
xlab="log(individuals)", ylab="Species count")
tempAcum <- spAcum(ssmat[2,])
lines(tempAcum$sp ~ tempAcum$ind, lwd=2)
# how do our samples at N match up to what we expected to see with that many
# individuals?
boxplot(x=aRich, at=sampleCount, add=TRUE, border="red", col=rgb(0,0,0,0))
tempAcum
tempAcum$ind - sampleCount
# what part of our accumulation line is closest to our sample count
aMCov <- which.min(tempAcum$ind - sampleCount)
aMCov
# what part of our accumulation line is closest to our sample count
aMCov <- which.min(abs(tempAcum$ind - sampleCount))
aMCov
aMCov <- tempAcum[c(aMCov, aMCov+1),]
aMCov
# what part of our accumulation line is closest to our sample count
aMCov <- which.min(abs(tempAcum$ind - sampleCount))
tempAcum$ind[aMCov]
aMCov <- ifelse(tempAcum$ind[aMCov] > sampleCount, c(0,-1), c(1,0))
aMCov <- tempAcum[aMCov,]
aMCov <- tempAcum[aMCov,]
# what part of our accumulation line is closest to our sample count
aMCov <- which.min(abs(tempAcum$ind - sampleCount))
aMCov <- ifelse(tempAcum$ind[aMCov] > sampleCount, c(0,-1), c(1,0))
aMCov <- tempAcum[aMCov,]
aMCov
# what part of our accumulation line is closest to our sample count
aMCov <- which.min(abs(tempAcum$ind - sampleCount))
aMCov
# what part of our accumulation line is closest to our sample count
aMCov <- which.min(abs(tempAcum$ind - sampleCount))
# what part of our accumulation line is closest to our sample count
aMCov <- which.min(abs(tempAcum$ind - sampleCount))
if(tempAcum$ind[aMCov] > sampleCount){
aMCov <- c(0,-1) } else { aMCov <- c(1,0) }
aMCov <- tempAcum[aMCov,]
aMCov
# what part of our accumulation line is closest to our sample count
aMCov <- which.min(abs(tempAcum$ind - sampleCount))
aMCov
if(tempAcum$ind[aMCov] > sampleCount){
aMCov <- c(0,-1) } else { aMCov <- c(1,0) }
aMCov
# what part of our accumulation line is closest to our sample count
aMCov <- which.min(abs(tempAcum$ind - sampleCount))
if(tempAcum$ind[aMCov] > sampleCount){
aMCovAdj <- c(0,-1) } else { aMCovAdj <- c(1,0) }
aMCov <- tempAcum[aMCov + aMCovAdj,]
aMCov
# now slope is the dY/dX
manCov <- diff(aMCov$sp / aMCov$ind)
manCov
# now slope is the dY/dX, and coverage is 1 minus the slope
manCov <- 1 - diff(aMCov$sp / aMCov$ind)
manCov
?estimateD
aSamp[[1]]
str(aSamp)
aSamp[,1]
# now thanks to the big daddy of computers, Alan Turing, and big brains like
# Anne Chao and John Alroy, we can predict coverage by looking at the number
# of species we only found once, or twice, which tells us something about how
# many might be left to find).
estimateD(aSamp[,1], base="coverage")
# now thanks to the big daddy of computers, Alan Turing, and big brains like
# Anne Chao and John Alroy, we can predict coverage by looking at the number
# of species we only found once, or twice, which tells us something about how
# many might be left to find).
estimateD(aSamp[,1], level=0.5, base="coverage")
estimateD
invChat
iNEXT:::invChat
iNEXT:::Chat.Sam()
iNEXT:::Chat.Sam
# now the actual part of the iNEXT package that calculates coverage is hidden
# within the estimateD function, and then within the hidden invChat function,
# You can look at it with "iNEXT:::Chat.Sam. It needs two arguments, both of
# which we can get from our sample data
iNEXT:::Chat.Sam(aSamp[,1], 2*max(aSamp[,1]))
# now the actual part of the iNEXT package that calculates coverage is hidden
# within the estimateD function, and then within the hidden invChat function,
# You can look at it with "iNEXT:::Chat.Sam. It needs two arguments, both of
# which we can get from our sample data
iNEXT:::Chat.Sam(aSamp[,2], 2*max(aSamp[,2]))
invChat.Sam
iNEXT:::invChat.Sam
# now the actual part of the iNEXT package that calculates coverage is hidden
# within the estimateD function, and then within the hidden invChat function,
# You can look at it with "iNEXT:::Chat.Sam. It needs two arguments, both of
# which we can get from our sample data.
a <- iNEXT:::Chat.Sam(aSamp[,2], 2*max(aSamp[,2]))
out <- invChat.Ind(aSamp[,2], a, 0.95)
out <- iNEXT:::invChat.Ind(aSamp[,2], a, 0.95)
out
out <- iNEXT:::invChat.Ind(aSamp[,2], a, 0.95)
iNEXT:::invChat.Ind
custom <- function (x, C, conf = NULL)
{
m <- NULL
n <- sum(x)
refC <- Chat.Ind(x, n)
f <- function(m, C) abs(Chat.Ind(x, m) - C)
if (refC > C) {
opt <- optimize(f, C = C, lower = 0, upper = sum(x))
mm <- opt$minimum
mm <- round(mm)
}
if (refC <= C) {
f1 <- sum(x == 1)
f2 <- sum(x == 2)
if (f1 > 0 & f2 > 0) {
A <- (n - 1) * f1/((n - 1) * f1 + 2 * f2)
}
if (f1 > 1 & f2 == 0) {
A <- (n - 1) * (f1 - 1)/((n - 1) * (f1 - 1) + 2)
}
if (f1 == 1 & f2 == 0) {
A <- 1
}
if (f1 == 0 & f2 == 0) {
A <- 1
}
mm <- (log(n/f1) + log(1 - C))/log(A) - 1
mm <- n + mm
mm <- round(mm)
}
if (mm > 2 * n)
thod <- ifelse(mm < n, "interpolated", ifelse(mm == n,
"observed", "extrapolated"))
if (is.null(conf)) {
out <- data.frame(m = mm, method = method, SamCov = round(Chat.Ind(x,
mm), 3), SpeRic = round(Dqhat.Ind(x, 0, mm), 3),
ShaDiv = round(Dqhat.Ind(x, 1, mm), 3), SimDiv = round(Dqhat.Ind(x,
2, mm), 3))
colnames(out) <- c("m", "method", "SC", "q = 0", "q = 1",
"q = 2")
}
else {
tmp0 <- iNEXT.Ind(x, q = 0, m = c(1, mm), se = TRUE,
conf = conf)
tmp1 <- iNEXT.Ind(x, q = 1, m = c(1, mm), se = TRUE,
conf = conf)
tmp2 <- iNEXT.Ind(x, q = 2, m = c(1, mm), se = TRUE,
conf = conf)
tmp <- subset(rbind(tmp0, tmp1, tmp2), m == mm)
out <- tmp[, c(1, 2, 3, 7, 4, 5, 6)]
out[, 4:7] <- round(out[, 4:7], 3)
}
out
}
out <- custom(aSamp[,2], a, 0.95)
custom <- function (x, C, conf = NULL)
{
m <- NULL
n <- sum(x)
refC <- iNEXT:::Chat.Ind(x, n)
f <- function(m, C) abs(iNEXT:::Chat.Ind(x, m) - C)
if (refC > C) {
opt <- optimize(f, C = C, lower = 0, upper = sum(x))
mm <- opt$minimum
mm <- round(mm)
}
if (refC <= C) {
f1 <- sum(x == 1)
f2 <- sum(x == 2)
if (f1 > 0 & f2 > 0) {
A <- (n - 1) * f1/((n - 1) * f1 + 2 * f2)
}
if (f1 > 1 & f2 == 0) {
A <- (n - 1) * (f1 - 1)/((n - 1) * (f1 - 1) + 2)
}
if (f1 == 1 & f2 == 0) {
A <- 1
}
if (f1 == 0 & f2 == 0) {
A <- 1
}
mm <- (log(n/f1) + log(1 - C))/log(A) - 1
mm <- n + mm
mm <- round(mm)
}
if (mm > 2 * n)
thod <- ifelse(mm < n, "interpolated", ifelse(mm == n,
"observed", "extrapolated"))
if (is.null(conf)) {
out <- data.frame(m = mm, method = method, SamCov = round(iNEXT:::Chat.Ind(x,
mm), 3), SpeRic = round(iNEXT:::Dqhat.Ind(x, 0, mm), 3),
ShaDiv = round(iNEXT:::Dqhat.Ind(x, 1, mm), 3), SimDiv = round(iNEXT:::Dqhat.Ind(x,
2, mm), 3))
colnames(out) <- c("m", "method", "SC", "q = 0", "q = 1",
"q = 2")
}
else {
tmp0 <- iNEXT:::iNEXT.Ind(x, q = 0, m = c(1, mm), se = TRUE,
conf = conf)
tmp1 <- iNEXT:::iNEXT.Ind(x, q = 1, m = c(1, mm), se = TRUE,
conf = conf)
tmp2 <- iNEXT:::iNEXT.Ind(x, q = 2, m = c(1, mm), se = TRUE,
conf = conf)
tmp <- subset(rbind(tmp0, tmp1, tmp2), m == mm)
out <- tmp[, c(1, 2, 3, 7, 4, 5, 6)]
out[, 4:7] <- round(out[, 4:7], 3)
}
out
}
out <- custom(aSamp[,2], a, 0.95)
C
a
# now the actual part of the iNEXT package that calculates coverage is hidden
# within the estimateD function, and then within the hidden invChat function,
# You can look at it with "iNEXT:::Chat.Sam. It needs two arguments, both of
# which we can get from our sample data.
a <- iNEXT:::Chat.Sam(aSamp[,2], 2*max(aSamp[,2]))
2*max(aSamp[,2])
aSamp[,2]
# now the actual part of the iNEXT package that calculates coverage is hidden
# within the estimateD function, and then within the hidden invChat function,
# You can look at it with "iNEXT:::Chat.Sam. It needs two arguments, both of
# which we can get from our sample data.
aAbund <- table(aSamp[,2])
aAbund
a <- iNEXT:::Chat.Sam(aAbund, 2*max(aAbund))
a
out <- iNEXT:::invChat(aAbund, a, 0.95)
# now the actual part of the iNEXT package that calculates coverage is hidden
# within the estimateD function, and then within the hidden invChat function,
# You can look at it with "iNEXT:::Chat.Sam. It needs two arguments, both of
# which we can get from our sample data.
aAbund <- as.vector(table(aSamp[,2]))
aAbund
data(spider)
spider
data(ant)
ant
a <- iNEXT:::Chat.Sam(aAbund, 2*max(aAbund))
a
out <- iNEXT:::invChat(aAbund, a, 0.95)
estimaeD(aAbund)
estimateD(aAbund)
manCov
x<-aSamp[,1]
estimateD(as.vector(table(x)))$SC
# Let's do this for all our samples
aCov <- apply(aSamp, 2, function(x){
estimateD(as.vector(table(x)))$SC[1]
})
?apply
# Let's do this for all our samples
aAbund <- apply(aSamp, 2, function(x){ as.vector(table(x))})
aAbund
aEstD <- estimateD(aAbund[[1:10]])
aAbund[[1:10]]
aAbund[[1]]
aEstD <- estimateD(aAbund[1:10])
aEstD
?estimateD
aEstD <- estimateD(aAbund[1:10], base="size")
aEstD
aEstD <- estimateD(aAbund[1:10], base="coverage")
aEstD
aEstD <- estimateD(aAbund, base="coverage")
# Let's do this for all our samples (well, 50, given the function takes a while to run)
aAbund <- apply(aSamp, 2, function(x){ as.vector(table(x))})
aEstD <- estimateD(aAbund[1:50], base="coverage")
aEstD
aEstCov <- aEstD$SC[aEstD$order==1,]
aEstCov <- aEstD$SC[aEstD$order==1]
aEstCov
mean(aEstCov)
# our manual slope
manCov
# the estimated one from our abundance subsamples
median(aEstCov)
dEstD <- estimateD(apply(dSamp, 2, function(x){ as.vector(table(x))})[1:20],
base="coverage")
rEstD <- estimateD(apply(rSamp, 2, function(x){ as.vector(table(x))})[1:20],
base="coverage")
median(dEstD$SC[dEstD$order==1])
median(aEstD$SC[aEstD$order==1])
median(rEstD$SC[rrEstD$order==1])
median(rEstD$SC[rEstD$order==1])
# our manual slope coverage...
manCov
# the estimated one from our abundance subsamples
median(aEstCov)
# what part of our accumulation line is closest to our sample count
aMCov <- which.min(abs(tempAcum$ind - sampleCount))
if(tempAcum$ind[aMCov] > sampleCount){
aMCovAdj <- c(0,-1) } else { aMCovAdj <- c(1,0) }
aMCov <- tempAcum[aMCov + aMCovAdj,]
# now slope is the dY/dX, and coverage is 1 minus the slope
manCov <- 1 - diff(aMCov$sp / aMCov$ind)
manCov
aAbund <- as.vector(table(aSamp[,2]))
estimateD(aAbund)
# Let's do this for all our samples (well, 50, given the function takes a while to run)
aAbund <- apply(aSamp, 2, function(x){ as.vector(table(x))})
aEstD <- estimateD(aAbund[1:50], base="coverage")
aEstCov <- aEstD$SC[aEstD$order==1]
# our manual slope coverage...
manCov
# the estimated one from our abundance subsamples
median(aEstCov)
# the estimated one from our abundance subsamples
mean(aEstCov)
aEstCov
options(repos = c(getOption("repos"),
rstan = "http://wiki.stan.googlecode.com/git/R"))
install.packages('rstan', type = 'source')
install.packages('rstan', type = 'source')
install.packages('rstan', type = 'source')
install.packages('rstan', type = 'source')
install.packages('rstan', type = 'source')
install.packages('rstan')
install.packages("rstanarm")
library("rstanarm")
install.packages("brms")
library(brms)
install.packages("brms")
install.packages("brms")
install.packages("brms")
library(brms)
data(iris)
head(iris)
test <- brm(Sepal.Length ~ Species, data=iris)
plot(test)
rm(list=ls())
library(readxl)
library(d3r)
setwd("/home/timothy/Dropbox/Tim/CV/collabNetwork")
myName = "Timothy L. Staples"
myPapers <- read.csv("wos1.csv", stringsAsFactors = FALSE)
myCoAuth <- sort(unique(unlist(strsplit(myPapers$Author.Full.Names, "; ",))))
paste0("AU = (", paste0(myCoAuth, collapse = ") OR ("), ")")
# cycle through wos subfolder to import 500 paper blocks
wosFiles <- list.files(path="./wos", include.dirs=TRUE, pattern=".xls")
coAuthPapers <- do.call("rbind", lapply(1:length(wosFiles), function(n){
temp <- as.data.frame(read_excel(paste0("./wos/", wosFiles[n])),
stringAsFactors=FALSE)
authorList <- strsplit(temp$`Author Full Names`, "; ")
do.call("rbind", lapply(1:length(authorList), function(n1){
data.frame(auth = authorList[[n1]],
pID = ((n-1)*500) + n1,
pubYear = temp$`Publication Year`[n1])
}))
}))
coAuthPapers$surname <- substr(coAuthPapers$auth,
1, regexpr(", ", coAuthPapers$auth)-1)
coAuthPapers$first <- substr(coAuthPapers$auth,
regexpr(", ", coAuthPapers$auth)+2,
nchar(as.character(coAuthPapers$auth)))
coAuthPapers$full <- paste0(coAuthPapers$first, " ", coAuthPapers$surname)
# make "me" the year of publication
head(coAuthPapers)
# now make a co-author table, only including my co-authors
coAuthPapers <- droplevels(coAuthPapers[coAuthPapers$auth %in% myCoAuth,])
# now make me a year
myPubYears <- sort(unique(coAuthPapers$pubYear[coAuthPapers$full  %in% c(myName, "Timothy Staples")]))
coAuthPapers$full[coAuthPapers$full %in% c(myName, "Timothy Staples")] = coAuthPapers$pubYear[coAuthPapers$full  %in% c(myName, "Timothy Staples")]
coAuthMat <- do.call("rbind",
tapply(coAuthPapers$full,
coAuthPapers$pID,
function(x){expand.grid(x, x)}, simplify=FALSE))
coAuthMat <- table(coAuthMat$Var1, coAuthMat$Var2)
aTab <- data.frame(source = rep(rownames(coAuthMat), ncol(coAuthMat)),
target = rep(colnames(coAuthMat), each=nrow(coAuthMat)),
count=as.vector(coAuthMat), stringsAsFactors = FALSE)
for(n in 1:(length(myPubYears)-1)){
aTab$count[aTab$source %in% myPubYears[n] &
aTab$target %in% myPubYears[n+1]] = 1
}
aTab <- aTab[aTab$source != aTab$target,]
aTab <- aTab[aTab$count > 0,]
aTab$primary <- ifelse((aTab$source %in% myPubYears | aTab$target %in% myPubYears),
"#324158", "#8C96A6")
aTab$width <- ifelse(aTab$source %in% myPubYears | aTab$target %in% myPubYears, 2, 0.5)
aTab$width[aTab$source %in% myPubYears & aTab$target %in% myPubYears] = 7.5
countWithMe <- sapply(split(aTab, f=aTab$target), function(x){
if(x$target %in% myPubYears){return(4)}
sum(x$count[x$source %in% c(myPubYears)])
})
# convert table into graph
library(igraph)
network=graph_from_data_frame(d=aTab, directed=F)
V(network)$count = countWithMe[match(V(network)$name, names(countWithMe))]
V(network)$count <- ifelse(V(network)$count == 0, 5, 3.5*V(network)$count)
# V(network)$count[V(network)$name == myName] = 15
V(network)$primary = "#324158"
V(network)$primary[V(network)$name %in% myPubYears] = "white"
V(network)$label = V(network)$name
V(network)$shadow = "rgb(255, 255, 255) 2px 0px 0px, rgb(255, 255, 255) 1.75517px 0.958851px 0px, rgb(255, 255, 255) 1.0806px 1.68294px 0px, rgb(255, 255, 255) 0.141474px 1.99499px 0px, rgb(255, 255, 255) -0.832294px 1.81859px 0px, rgb(255, 255, 255) -1.60229px 1.19694px 0px, rgb(255, 255, 255) -1.97999px 0.28224px 0px, rgb(255, 255, 255) -1.87291px -0.701566px 0px, rgb(255, 255, 255) -1.30729px -1.51361px 0px, rgb(255, 255, 255) -0.421592px -1.95506px 0px, rgb(255, 255, 255) 0.567324px -1.91785px 0px, rgb(255, 255, 255) 1.41734px -1.41108px 0px, rgb(255, 255, 255) 1.92034px -0.558831px 0px"
V(network)$shadow[V(network)$name %in% myPubYears] = "rgb(50, 65, 88) 2px 0px 0px, rgb(50, 65, 88) 1.75517px 0.958851px 0px, rgb(50, 65, 88) 1.0806px 1.68294px 0px, rgb(50, 65, 88) 0.141474px 1.99499px 0px, rgb(50, 65, 88) -0.832294px 1.81859px 0px, rgb(50, 65, 88) -1.60229px 1.19694px 0px, rgb(50, 65, 88) -1.97999px 0.28224px 0px, rgb(50, 65, 88) -1.87291px -0.701566px 0px, rgb(50, 65, 88) -1.30729px -1.51361px 0px, rgb(50, 65, 88) -0.421592px -1.95506px 0px, rgb(50, 65, 88) 0.567324px -1.91785px 0px, rgb(50, 65, 88) 1.41734px -1.41108px 0px, rgb(50, 65, 88) 1.92034px -0.558831px 0px"
# add coordinates for each year
yearVs <- !is.na(as.numeric(V(network)$name))
yearYs <- seq(-length(yearVs), length(yearVs), len=sum(yearVs))
V(network)$cat = 0
V(network)$cat[yearVs] = yearYs
V(network)$catStrength = as.numeric(yearVs)
url <- read.csv("url.csv")
V(network)$url = NA
V(network)$url[match(url$name,
V(network)$name)] = url$url
V(network)$hasurl <- !is.na(V(network)$url)
V(network)$url
url$url
V(network)$url = NA
V(network)$url[match(url$name,
V(network)$name)] = as.character(url$url)
V(network)$url
V(network)$hasurl <- !is.na(V(network)$url)
V(network)$offlabel = V(network)$name
V(network)$offlabel[V(network)$name %in% myCoAuth]=""
V(network)$offlabel[match(url$name,
V(network)$name)]= url$label
V(network)$width = 0
V(network)$width[V(network)$name %in% myPubYears] = 5
V(network)$strokeCol = "#324158"
V(network)$strokeCol[V(network)$name %in% myPubYears] = "#324158"
# Transform it in a JSON format for d3.js
data_json <- d3_igraph(network)
# Save this file
write(data_json, "/home/timothy/Dropbox/Tim/CV/collabNetwork/data.json")
url$label
url <- read.csv("url.csv")
V(network)$url = NA
V(network)$url[match(url$name,
V(network)$name)] = as.character(url$url)
V(network)$hasurl <- !is.na(V(network)$url)
V(network)$offlabel = V(network)$name
V(network)$offlabel[V(network)$name %in% myCoAuth]=""
V(network)$offlabel[match(url$name,
V(network)$name)]= as.character(url$label)
V(network)$width = 0
V(network)$width[V(network)$name %in% myPubYears] = 5
V(network)$strokeCol = "#324158"
V(network)$strokeCol[V(network)$name %in% myPubYears] = "#ffffff"
# Transform it in a JSON format for d3.js
data_json <- d3_igraph(network)
# Save this file
write(data_json, "/home/timothy/Dropbox/Tim/CV/collabNetwork/data.json")
V(network)$width = 0
V(network)$width[V(network)$name %in% myPubYears] = 5
V(network)$strokeCol = "#324158"
V(network)$strokeCol[V(network)$name %in% myPubYears] = "#324158"
# Transform it in a JSON format for d3.js
data_json <- d3_igraph(network)
# Save this file
write(data_json, "/home/timothy/Dropbox/Tim/CV/collabNetwork/data.json")
